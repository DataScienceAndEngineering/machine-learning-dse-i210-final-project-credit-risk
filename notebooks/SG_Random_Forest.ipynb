{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from utils.merge_tools import merge_n_case_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:/Kaggle_Credit_Risk_Predictions/new_aggs/new_aggs'\n",
    "base_file = 'D:/Kaggle_Credit_Risk_Predictions/parquet_files/train/train_base.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_n_case_ids(\n",
    "    n_ids: int = 1000,\n",
    "    data_dir: str = 'D:/Kaggle_Credit_Risk_Predictions/new_aggs/new_aggs',\n",
    "    path_to_base: str = 'D:/Kaggle_Credit_Risk_Predictions/parquet_files/train/train_base.parquet',\n",
    "    use_0: bool = True,\n",
    "    as_pandas: bool = True,\n",
    "    random_state: int = 28\n",
    ") -> pl.DataFrame | pd.DataFrame:\n",
    "    '''\n",
    "    Function to merge selected case_id from parquet files, returns subset case_id from the merged dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_ids : Number of case_ids to sample initially and return (int)\n",
    "    data_dir : Path to processed parquet files directory (str)\n",
    "    path_to_base : Path to base file (str)\n",
    "    use_0 : Use num_group1 == 0 (bool)\n",
    "    as_pandas : Return as pandas DataFrame\n",
    "    random_seed : Random seed (int)\n",
    "    '''\n",
    "    # Read the base dataframe and sample case_ids\n",
    "    if as_pandas:\n",
    "        base_df = pd.read_parquet(path_to_base)\n",
    "        case_ids = base_df['case_id'].sample(n=n_ids, replace=False, random_state=random_state).tolist()\n",
    "    else:\n",
    "        base_df = pl.read_parquet(path_to_base)\n",
    "        case_ids = base_df['case_id'].sample(n=n_ids, replace=False, seed=random_state).to_list()\n",
    "\n",
    "    # Define the file pattern for fetching files\n",
    "    file_pattern = '*grouped_0.parquet' if use_0 else '*grouped_rest.parquet'\n",
    "    file_paths = glob(data_dir + '/' + file_pattern)\n",
    "\n",
    "    # Initialize the merged DataFrame filtering the base DataFrame\n",
    "    if as_pandas:\n",
    "        df = base_df[base_df['case_id'].isin(case_ids)]\n",
    "    else:\n",
    "        df = base_df.filter(pl.col('case_id').is_in(case_ids))\n",
    "\n",
    "    # Merge DataFrames with only the selected case_ids\n",
    "    for path in file_paths:\n",
    "        if as_pandas:\n",
    "            temp = pd.read_parquet(path)\n",
    "            temp = temp[temp['case_id'].isin(case_ids)]\n",
    "            df = pd.merge(df, temp, on='case_id', how='outer')\n",
    "        else:\n",
    "            temp = pl.read_parquet(path)\n",
    "            temp = temp.filter(pl.col('case_id').is_in(case_ids))\n",
    "            df = df.join(temp, on='case_id', how='outer')\n",
    "\n",
    "    # Convert to pandas if required and using Polars\n",
    "    if as_pandas and isinstance(df, pl.DataFrame):\n",
    "        df = df.to_pandas()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_n_case_ids(\n",
    "    n_ids=1000,\n",
    "    data_dir='D:/Kaggle_Credit_Risk_Predictions/new_aggs/new_aggs',\n",
    "    path_to_base='D:/Kaggle_Credit_Risk_Predictions/parquet_files/train/train_base.parquet',\n",
    "    use_0=True,\n",
    "    as_pandas=True,\n",
    "    random_state=28  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#case_ids_list = list(df['case_id'])\n",
    "\n",
    "df_rest = merge_n_case_ids(\n",
    "    n_ids=1000,\n",
    "    data_dir=data_dir,\n",
    "    path_to_base=base_file,\n",
    "    use_0=False,\n",
    "    as_pandas=True,\n",
    "    random_state=28\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_rest, how='left', on='case_id', suffixes=(\"\", \"_r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>date_decision</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WEEK_NUM</th>\n",
       "      <th>target</th>\n",
       "      <th>actualdpd_943P_min</th>\n",
       "      <th>annuity_853A_min</th>\n",
       "      <th>byoccupationinc_3656910L_min</th>\n",
       "      <th>childnum_21L_min</th>\n",
       "      <th>credacc_actualbalance_314A_min</th>\n",
       "      <th>...</th>\n",
       "      <th>employername_160M_binary_7_r</th>\n",
       "      <th>employername_160M_binary_8_r</th>\n",
       "      <th>employername_160M_binary_9_r</th>\n",
       "      <th>employername_160M_binary_10_r</th>\n",
       "      <th>employername_160M_binary_11_r</th>\n",
       "      <th>employername_160M_binary_12_r</th>\n",
       "      <th>employername_160M_binary_13_r</th>\n",
       "      <th>employername_160M_binary_14_r</th>\n",
       "      <th>employername_160M_binary_15_r</th>\n",
       "      <th>employername_160M_binary_16_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4927</td>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>201902</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7449</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>201903</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7786</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>201903</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1952.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8275</td>\n",
       "      <td>2019-03-16</td>\n",
       "      <td>201903</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10950</td>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>201904</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2641 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id date_decision   MONTH  WEEK_NUM  target  actualdpd_943P_min  \\\n",
       "0     4927    2019-02-15  201902         6       1                 NaN   \n",
       "1     7449    2019-03-11  201903         9       0                 NaN   \n",
       "2     7786    2019-03-12  201903        10       0                 0.0   \n",
       "3     8275    2019-03-16  201903        10       0                 NaN   \n",
       "4    10950    2019-04-09  201904        14       0                 NaN   \n",
       "\n",
       "   annuity_853A_min  byoccupationinc_3656910L_min  childnum_21L_min  \\\n",
       "0               NaN                           NaN               NaN   \n",
       "1               NaN                           NaN               NaN   \n",
       "2            1952.8                           NaN               NaN   \n",
       "3               NaN                           NaN               NaN   \n",
       "4               NaN                           NaN               NaN   \n",
       "\n",
       "   credacc_actualbalance_314A_min  ...  employername_160M_binary_7_r  \\\n",
       "0                             NaN  ...                           1.0   \n",
       "1                             NaN  ...                           0.0   \n",
       "2                             NaN  ...                           0.0   \n",
       "3                             NaN  ...                           0.0   \n",
       "4                             NaN  ...                           0.0   \n",
       "\n",
       "   employername_160M_binary_8_r  employername_160M_binary_9_r  \\\n",
       "0                           0.0                           1.0   \n",
       "1                           1.0                           0.0   \n",
       "2                           1.0                           0.0   \n",
       "3                           1.0                           1.0   \n",
       "4                           1.0                           1.0   \n",
       "\n",
       "   employername_160M_binary_10_r  employername_160M_binary_11_r  \\\n",
       "0                            1.0                            0.0   \n",
       "1                            1.0                            1.0   \n",
       "2                            1.0                            1.0   \n",
       "3                            1.0                            1.0   \n",
       "4                            0.0                            0.0   \n",
       "\n",
       "   employername_160M_binary_12_r  employername_160M_binary_13_r  \\\n",
       "0                            1.0                            1.0   \n",
       "1                            1.0                            1.0   \n",
       "2                            1.0                            0.0   \n",
       "3                            1.0                            0.0   \n",
       "4                            1.0                            1.0   \n",
       "\n",
       "  employername_160M_binary_14_r employername_160M_binary_15_r  \\\n",
       "0                           0.0                           1.0   \n",
       "1                           1.0                           1.0   \n",
       "2                           1.0                           1.0   \n",
       "3                           1.0                           1.0   \n",
       "4                           0.0                           1.0   \n",
       "\n",
       "   employername_160M_binary_16_r  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "\n",
       "[5 rows x 2641 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float64    2495\n",
       "int8         99\n",
       "object       30\n",
       "uint32        8\n",
       "int64         7\n",
       "int32         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2641)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty columns\n",
    "df = df.dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2524)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract date info from base\n",
    "df['date_decision'] = pd.to_datetime(df['date_decision'])\n",
    "df['dec_day'] = df['date_decision'].dt.day\n",
    "df['dec_month'] = df['date_decision'].dt.month\n",
    "df['dec_year'] = df['date_decision'].dt.year\n",
    "\n",
    "# Drop redundant information\n",
    "df = df.drop(columns=[\n",
    "    'MONTH', 'MONTH_r', 'WEEK_NUM', 'WEEK_NUM_r', \n",
    "    'date_decision', 'date_decision_r','case_id',\n",
    "    'target_r'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bool cols with na\n",
    "na_bool_cols = df.select_dtypes(include=['O']).columns\n",
    "\n",
    "# Remove redundant\n",
    "na_bool_cols = [ col for col in na_bool_cols if col.__contains__('min') ]\n",
    "df = df.drop(columns=na_bool_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create null flags\n",
    "na_cols = df.columns[df.isna().any()].to_list()\n",
    "isna_cols = [ col + '_isna' for col in na_cols ]\n",
    "na_df = df[na_cols].isna()\n",
    "na_df.columns = isna_cols\n",
    "\n",
    "df = pd.concat([df, na_df], axis=1)\n",
    "\n",
    "# Free memory\n",
    "del na_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns below treshold\n",
    "df = df.dropna(thresh=len(df)//10, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='target')\n",
    "y = df[['target']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=28)\n",
    "\n",
    "# Free memory\n",
    "del df, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool       2354\n",
       "float64    1595\n",
       "int8         99\n",
       "object        8\n",
       "uint32        8\n",
       "int32         5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill na from X_train median and mode\n",
    "X_train[X_train.select_dtypes(exclude=['O', 'bool']).columns] = X_train.select_dtypes(exclude=['O', 'bool']).fillna(X_train.median())\n",
    "X_test[X_test.select_dtypes(exclude=['O', 'bool']).columns] = X_test.select_dtypes(exclude=['O', 'bool']).fillna(X_train.median())\n",
    "X_train[X_train.select_dtypes(include=['O', 'bool']).columns] = X_train.select_dtypes(include=['O', 'bool']).fillna(X_train.mode())\n",
    "X_test[X_test.select_dtypes(include=['O', 'bool']).columns] = X_test.select_dtypes(include=['O', 'bool']).fillna(X_train.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_na_cols = X_train.columns[X_train.isna().any()].to_list()\n",
    "for col in remain_na_cols:\n",
    "    X_train[col] = X_train[col].fillna(X_train[col].mode()[0])\n",
    "    X_test[col] = X_test[col].fillna(X_train[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=28)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
